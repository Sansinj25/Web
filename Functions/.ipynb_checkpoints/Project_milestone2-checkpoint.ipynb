{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - The Food symphony ðŸ¥™\n",
    " <p><div class=\"lev1\"><a href=\"#1/-Introduction-of-the-structure\"><span class=\"toc-item-num\">1.&nbsp;&nbsp;</span>Introduction of the structure</a></div>\n",
    "  <div class=\"lev3\"><a href=\"#2/-Preprocessing-the-ingredients-data-(Missing-values,-upper-cases,-natural-language-processing)\"><span class=\"toc-item-num\">2.&nbsp;&nbsp;</span>Preprocessing the ingredients data (Missing values, upper cases, natural language processing)</a></div>\n",
    "  <div class=\"lev3\"><a href=\"#3/-Co-occurences-and-Covariance\"><span class=\"toc-item-num\">3.&nbsp;&nbsp;</span>Co-occurences and Covariance</a></div>\n",
    "  <div class=\"lev3\"><a href=\"#4/-Linear-Regression\"><span class=\"toc-item-num\">4.&nbsp;&nbsp;</span>Linear Regression</a></div>\n",
    "  <div class=\"lev3\"><a href=\"#5/-Next-step-and-final-goal\"><span class=\"toc-item-num\">5.&nbsp;&nbsp;</span>Next step and final goal</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ Introduction of the structure\n",
    "First of all, in this section, we remind and describe in detail the overall structure of the our project: the steps and the goals.\n",
    "\n",
    "The diagram below gives an illustrated overview:\n",
    "\n",
    "<img src=\"Structure.jpeg\" width=900>\n",
    "\n",
    "The diagram illustrates the work we have been doing until now for the food symphony project. The first partÂ consistsÂ in filtering the raw data in order to get a clean data set where we could do some analysis and perform machine learning algorithms on it.\n",
    "\n",
    "The most important step in the first part of the project  and the most time consuming  was to design filters that enable us to get a proper data set to analyse. Indeed, we had to deal with a lot of different typos containing valid information. Instead of skipping data,  we did our best to drag out all the available information.\n",
    "\n",
    "The first filtering step was to deal with special characters and filter useless parenthesis. After this first filtering step, we decide to create 3 lists in order to select theÂ ingredientsÂ that had the information about quantity, unit,Â ingredientsÂ and the technics to apply for each ingredient. The ones that didnâ€™t have all this information were not taken into account.Â \n",
    "\n",
    "The unit list, was created by hand, by checkingÂ information inÂ Wikipedia. The techniques list was done by usingÂ the raw data, and taking all the verbs in the past tense. TheÂ ingredientsÂ list was create by web scraping. \n",
    "Once the filteringÂ is done, we create a data frame with the columns asÂ the ingredientsÂ and the raw theÂ recipes.\n",
    " We create theÂ co-occurrenceÂ matrix and the covariance matrix to make a first analysis, and weÂ will useÂ them in order to create newÂ recipes.\n",
    " \n",
    "Additionally, we generate a data frame containing diverseÂ nutrientÂ information byÂ ingredient. This dataset will be veryÂ helpfulÂ to improve our current results in the prediction of theÂ recipeÂ calories contempt, while usingÂ linear regression models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ----- Librairies ----- #\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import pos_tag\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import brown\n",
    "import webcolors\n",
    "from IPython.display import display\n",
    "sys.path.append(\"..\")\n",
    "from ADA_JEX2017.Project.Functions.str_functions import *\n",
    "from ADA_JEX2017.Project.Functions.pre_process import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- Loading the dataset'recipeInfo_WestWhiteHorvitz_WWW2013.csv' ----- #\n",
    "path='../ADA_JEX2017/Project/Functions/'\n",
    "\n",
    "data_file='./recipeInfo/recipeInfo_WestWhiteHorvitz_WWW2013.csv'\n",
    "raw_data = pd.read_csv(data_file ,sep=';')\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizing nutrients data\n",
    "Extract the nutrients from the dataset which will be used it the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutri_data=raw_data[['title','kcal_total','kcal_carb','kcal_fat','kcal_protein','mg_sodium','mg_cholesterol']].copy()\n",
    "nutri_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating useful lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we are loading lists (ingredient_list.txt, units_list.txt, technique_list.txt) which were created previously using the the function in 'list_creation.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----- Initializing and loading the list of techniques, units and ingredients created previously ----- #\n",
    "with open(path+'units_list.txt', 'r') as f:\n",
    "    units_list = [line.rstrip('\\n') for line in f]\n",
    "    \n",
    "with open(path+'technique_list.txt', 'r') as f:\n",
    "    techniques_list = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "with open(path+'ingredient_list.txt', 'r') as f:\n",
    "    ingredient_list = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "# ----- Initialize lemmatizer and apply on the data ----- #\n",
    "# Lemmatizer is used to get the stem of each word in order to get a more homogeneous data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ingredient_list=[lemmatizer.lemmatize(token).lower() for token in ingredient_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/ Preprocessing the ingredients data (Missing values, upper cases, natural language processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Make a dataframe with our data while dropping the NaN values ----- #\n",
    "ingr_dataframe=raw_data[['title','ingredients_list','ingredients_bag-of-words']].copy().dropna()\n",
    "ingr_dataframe = ingr_dataframe.reset_index(drop=True)\n",
    "display(ingr_dataframe.head())\n",
    "\n",
    "# Ignore upper case in the ingredients list string\n",
    "ingr_dataframe['ingredients_list']=ingr_dataframe['ingredients_list'].str.lower()\n",
    "\n",
    "#ingr_data_reduced=ingr_dataframe.head(100) # create a reduced data as draft to test when creating new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----- Function to process the text in the ingredient list ----- #\n",
    "# We notice that for some ingredients in the ingredients list, the quantity is given twice with one quantity given in volume or mass within parenthesis\n",
    "# Therefore, we apply the next function to return only the wanted quantity\n",
    "fun_add_preprocess(ingr_dataframe,units_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of ingredients for each recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!! ----- Test cell : to inspect a specific recipe ----- !!!!!! #\n",
    "receipe=ingr_dataframe.loc[0]['Recipe_preporcess']\n",
    "print(receipe)\n",
    "dic_ingr,dictec,wasted,wasted_numb=fun_extract_ingredients\\\n",
    "    (receipe,ingredient_list,techniques_list,units_list,to_gram=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- Use whole data frame to extract each ingredient with its quantity and unit by using the lists  ------ #\n",
    "\n",
    "ingr_data_reduced=ingr_dataframe.head(100)\n",
    "all_dic=[]\n",
    "not_used_ingr=[]\n",
    "wastes=0\n",
    "for index, row in ingr_dataframe.iterrows():\n",
    "    recipe=row['Recipe_preporcess']\n",
    "    # Function in str_functions.py to extract the ingredients for each recipe\n",
    "    dic_ingre,dictec,wasted_ingr,wasted_number=fun_extract_ingredients\\\n",
    "            (recipe,ingredient_list,techniques_list,units_list,to_gram=True)\n",
    "    # Also convert each quantity in the same unit (grams) if to_gram is set to True\n",
    "    all_dic.append(dic_ingre)\n",
    "\n",
    "# We implemented the number of ingredients which didn't fit the criteria \n",
    "# Then we plotted the ingredient that we threw away in order to complete manually our ingredient list with important ingredients that our list may miss\n",
    "    #not_used_ingr.append(wasted_ingr) \n",
    "    #wastes=wastes+wasted_number\n",
    "    \n",
    "# ----- Create the dataframe of all the ingredient and their quantities ----- #\n",
    "ingredients_frame=pd.DataFrame(data=all_dic)\n",
    "display(ingredients_frame.head(5))\n",
    "\n",
    "# ----- Print the number of ingredients ----- #\n",
    "print('There are : ',len(list(ingredients_frame)), 'ingredients')\n",
    "ingred_used={}\n",
    "for i in list(ingredients_frame):\n",
    "    ingred_used[i]=sum(ingredients_frame[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Sort the ingredients by occurrence ----- #\n",
    "occu=sorted((value,key) for (key,value) in ingred_used.items())\n",
    "occu[::-1]\n",
    "\n",
    "ing_occ = pd.DataFrame(occu[::-1]).head(10)\n",
    "people = ing_occ[1].values\n",
    "score = ing_occ[0].values\n",
    "x_pos = np.arange(len(people))\n",
    "plt.figure(figsize=((20,10)))\n",
    "plt.barh(x_pos, score,align='center',color='#31a354')\n",
    "plt.yticks(x_pos, people) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ Co-occurences and Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-occurences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Using K-NN to find the the association between ingredient ----- #\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "newdf = ingredients_frame.notnull().astype('int')\n",
    "coocc = newdf.T.dot(newdf)\n",
    "display(coocc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity and best association of ingredients\n",
    "Using the co-occurence matrice we compute with the k- Nearest Neighbourg Regression, the proximity between ingredients and end up with a combination of ingredients which would be likely associated to a specific ingredient.\n",
    "\n",
    "For instance, for apple chutney we find ingredients that is great when they are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=0.4\n",
    "number_neighbors_toshow=5\n",
    "neigh = NearestNeighbors(number_neighbors_toshow,r)\n",
    "neigh.fit(coocc.values)\n",
    "\n",
    "b = neigh.kneighbors(coocc.values, return_distance=False)\n",
    "a = pd.DataFrame(b)\n",
    "d = dict(zip(range(len(ingredients_frame.columns)),list(ingredients_frame.columns)))\n",
    "a.replace(d, inplace=True)\n",
    "a.rename(index=d,inplace=True)\n",
    "a.loc['apple chutney'][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check similiraties between recipes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=0.4\n",
    "number_neighbors_toshow=5\n",
    "neigh = NearestNeighbors(number_neighbors_toshow,r)\n",
    "neigh.fit(newdf.values)\n",
    "b = neigh.kneighbors(coocc.values, return_distance=False)\n",
    "a = pd.DataFrame(b)\n",
    "d = dict(zip(range(len(ingredients_frame.columns)),list(ingredients_frame.columns)))\n",
    "a.replace(d, inplace=True)\n",
    "a.rename(index=d,inplace=True)\n",
    "a.loc['chicken']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance\n",
    "\n",
    "C_ij is the covariance between the i th and j th ingredients.\n",
    "\n",
    "Covariance is just unscaled correlation.  \n",
    "If a number at a certain position in the covariance matrix is large, then the variable that corresponds to that row and the variable that corresponds to that column change with one another. When one goes up, the other goes up. When one goes down, the other goes down. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "ratio_u_ingred={}\n",
    "test_ingredients_frame=ingredients_frame.copy()\n",
    "for ingred in list(ingredients_frame):\n",
    "    mean = ingredients_frame[ingred].apply(pd.to_numeric, errors='coerce').dropna(axis=0, how='any').mean()\n",
    "    if math.isnan(mean):\n",
    "        mean=1\n",
    "    test_ingredients_frame[ingred][ingredients_frame[ingred].astype(str).str.contains('u')]=mean\n",
    "    ratio_u_ingred[ingred]=\\\n",
    "    sum(ingredients_frame[ingred].dropna(axis=0, how='any').astype(str).str.contains('u'))/len(ingredients_frame[ingred].dropna(axis=0, how='any').astype(str).str.contains('u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingr_matrix=test_ingredients_frame.fillna(0).values.T\n",
    "covar=np.cov(ingr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = dict(zip(range(len(ingredients_frame.columns)),list(ingredients_frame.columns)))\n",
    "i=15\n",
    "print('With: ',d[i])\n",
    "arr = np.array(covar[i])\n",
    "topingr=arr.argsort()[-6:][::-1]\n",
    "print('you should try:')\n",
    "for x in topingr[:]:\n",
    "    print(d[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4/ Linear Regression\n",
    "With the linear regression on the nutrients information from the data, we will be able to compute an approximation of nutrient value for each ingredient so that we can approximate the nutrient value for the recipes which the value was missing in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "nutri_data=raw_data[['kcal_total','kcal_carb','kcal_fat','kcal_protein','mg_sodium','mg_cholesterol']].copy()\n",
    "a = nutri_data.replace('?',np.nan)\n",
    "a.dropna(axis=0,how='any',inplace=True)\n",
    "\n",
    "ingredients_frame=test_ingredients_frame\n",
    "ingredients_frame['Total'] = a['kcal_total']\n",
    "ingredients_frame['Carbohyd'] = a['kcal_fat']\n",
    "ingredients_frame['fat'] = a['kcal_fat']\n",
    "ingredients_frame['protein'] = a['kcal_protein']\n",
    "ingredients_frame['mg_sodium'] = a['mg_sodium']\n",
    "ingredients_frame['mg_cholestrol'] = a['mg_cholesterol']\n",
    "\n",
    "display(ingredients_frame)\n",
    "Train_set = ingredients_frame.dropna(subset=['Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X = Train_set.drop(['Total','Carbohyd','fat','protein','mg_sodium','mg_cholestrol'],axis=1)\n",
    "X = X.replace(np.nan,0)\n",
    "Y = Train_set['Total'] \n",
    "\n",
    "X_train = X[:20000]\n",
    "Y_train = Y[:20000]\n",
    "\n",
    "X_test = X[20000:]\n",
    "Y_test = Y[20000:]\n",
    "\n",
    "line_reg = LinearRegression()\n",
    "line_reg.fit(X_train ,Y_train)\n",
    "line_reg.coef_[np.where(line_reg.coef_ < 0)] = 0\n",
    "Y_predict = line_reg.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(Y_test,Y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5/ Next step and final goal\n",
    "\n",
    "- Check forÂ outliersÂ in the data in order to improve our results.\n",
    "ByÂ outliersÂ in theÂ recipesÂ we mean, quantities ofÂ ingredientsÂ that are aberrant while comparing with the quantities for the otherÂ ingredientsÂ in theÂ recipe.\n",
    "\n",
    "- Improve and optimize the linear regression by appling a better conversion between volume and grams\n",
    "\n",
    "- Use the covariance, co-occurence and the result of k-NN regression, to make new special recipe based on the association score of ingredients.\n",
    "\n",
    "- Try to form some clusters based on the nutrients in order to group ingredients into categories.\n",
    "\n",
    "- Implement constraints like vegan, gluten-free or low-calorie meals with the result from the linear regression\n",
    "\n",
    "\n",
    "Our goal will be to create newÂ recipesÂ and suggest special recipes from the work that have been done, we believe that it will be possible. SpecialÂ recipeÂ will be created with the help of the covariance matrix and the co-occurrence matrix. Futhermore the user will be able to addÂ constrainsÂ regarding the nutrients present in theÂ recipe, such as gluten free, vegan etc.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
